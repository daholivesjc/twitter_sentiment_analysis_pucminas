{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers import (\n",
    "    preprocessing\n",
    ")\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StringType, StructField, StructType, IntegerType, DateType, FloatType, ArrayType, LongType, MapType, DateType\n",
    "import warnings\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# instancia spark\n",
    "spark = SparkSession.builder \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .config(\"spark.jars.packages\", \"io.delta:delta-core_2.12:1.1.0\") \\\n",
    "    .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\") \\\n",
    "    .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\") \\\n",
    "    .config(\"spark.executor.memory\",\"24G\") \\\n",
    "    .config(\"spark.driver.memory\",\"24G\") \\\n",
    "    .config(\"spark.executor.cores\",\"8\") \\\n",
    "    .config(\"spark.default.parallelism\",\"8\") \\\n",
    "    .config(\"spark.serializer\",\"org.apache.spark.serializer.KryoSerializer\") \\\n",
    "    .config(\"spark.sql.execution.arrow.pyspark.enabled\",\"true\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base de dados do twitter ja classificada com sentimentos\n",
    "path = \"/home/daholive/Documents/twitter_ellection_brazil_v2/datasource/raw_kaggle/TweetsWithTheme_v2.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframe twitter com sentimentos classificados\n",
    "dataframe = spark.read.options(delimiter=';',header='True').csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label adjust\n",
    "dataframe = dataframe.withColumn(\"sentiment_map\", \n",
    "    F.when(F.col(\"sentiment\")==\"Negativo\", 0).otherwise(1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframe features\n",
    "rdd2 = dataframe.rdd.map(lambda x: (preprocessing(x.tweet_text),len(preprocessing(x.tweet_text).split()),x.sentiment_map))\n",
    "\n",
    "schema = StructType([       \n",
    "    StructField('features', StringType(), True),\n",
    "    StructField('tokens_count', IntegerType(), True),\n",
    "    StructField('label', IntegerType(), True),\n",
    "])\n",
    "\n",
    "df_features = spark.createDataFrame(rdd2, schema = schema)\n",
    "\n",
    "count_map = F.udf( \n",
    "    lambda x: len(x.split()),\n",
    "    IntegerType()     \n",
    ")\n",
    "\n",
    "df_features = df_features \\\n",
    "    .filter(F.col(\"features\")!=\"-\") \\\n",
    "    .filter( count_map(F.col(\"features\"))<30 ) \\\n",
    "    .dropDuplicates(subset = ['features'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = df_features.sampleBy(\"label\", fractions={0: 1, 1: 0.87}, seed=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features and labels\n",
    "features = train.select('features').rdd.flatMap(lambda x: x).collect()\n",
    "labels = np.array(train.select('label').rdd.flatMap(lambda x: x).collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.metrics import classification_report_imbalanced\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "\n",
    "def tf_idf_features(tokens, num_features):\n",
    "\n",
    "    try:\n",
    "        vectorizer = CountVectorizer(max_features=num_features)\n",
    "        vectorizer.fit(tokens)\n",
    "        X_vectorizer = vectorizer.transform(tokens)\n",
    "\n",
    "        tf_idf_transformer = TfidfTransformer()\n",
    "        tf_idf_transformer.fit(X_vectorizer)\n",
    "        X_train_tf_idf = tf_idf_transformer.transform(X_vectorizer)\n",
    "\n",
    "        return csr_matrix(np.array([np.pad(x, (0, num_features-len(x)), 'constant', constant_values=0) for x in X_train_tf_idf.toarray()]))\n",
    "    \n",
    "    except:\n",
    "        return csr_matrix([np.pad(np.array([0]), (0, 1999), 'constant', constant_values=0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## MODEL TESTS  LogisticRegression\n",
    "\n",
    "def train_and_show_scores(x_features: csr_matrix, num_features: int,y: np.array) -> None:\n",
    "\n",
    "    X_train_tf_idf = tf_idf_features(x_features, num_features)\n",
    "\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "        X_train_tf_idf, y, train_size=0.7, random_state=42\n",
    "    )\n",
    "\n",
    "    clf = LogisticRegression(\n",
    "        class_weight='balanced',\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    solvers = ['newton-cg', 'lbfgs', 'liblinear']\n",
    "    penalty = ['l2']\n",
    "    c_values = [100, 10, 1.0, 0.1, 0.01]\n",
    "    max_iter = [10000]\n",
    "    grid = dict(solver=solvers,penalty=penalty,C=c_values,max_iter=max_iter)\n",
    "    \n",
    "    kfold = StratifiedKFold(n_splits = 10, shuffle = True)\n",
    "\n",
    "    random_search_cv = RandomizedSearchCV(\n",
    "        estimator=clf,\n",
    "        param_distributions=grid,\n",
    "        n_jobs=-1, \n",
    "        cv=kfold,\n",
    "        n_iter=20\n",
    "    )\n",
    "\n",
    "    random_search_cv.fit(X_train, y_train)\n",
    "    y_pred_train = random_search_cv.predict(X_train)\n",
    "    y_pred_valid = random_search_cv.predict(X_valid)\n",
    "\n",
    "    print(classification_report_imbalanced(y_train, y_pred_train))\n",
    "    print(classification_report_imbalanced(y_valid, y_pred_valid))\n",
    "\n",
    "    return random_search_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lr = train_and_show_scores(features,2000,labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model prediction with new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lr.predict_proba(tf_idf_features(['Lula é um ótimo presidente'],2000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lr.predict(tf_idf_features(['Lula é um ótimo presidente'],2000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model prediction with new tweets data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_tweets = \"/home/daholive/Documents/twitter_ellection_brazil_v2/datasource/trusted/tweets_preprocessing\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets = spark.read.parquet(path_tweets).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets['tf_idf'] = df_tweets['text_clean'].apply(lambda x: tf_idf_features([x],2000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets['sentiment'] = [model_lr.predict(mtx)[0] for mtx in df_tweets['tf_idf']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets.to_pickle('/home/daholive/Documents/twitter_ellection_brazil_v2/datasource/refined/tweets_logistic_regression/tweets_logistic_regression.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df_tweets = pd.read_pickle('/home/daholive/Documents/twitter_ellection_brazil_v2/datasource/refined/tweets_logistic_regression/tweets_logistic_regression.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets_resume = df_tweets[['query','created_at_tz','sentiment']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets_analysis = df_tweets_resume.groupby(['query','created_at_tz','sentiment']).agg(\n",
    "    {\n",
    "        'sentiment':'count'\n",
    "    }\n",
    ").rename(columns={'sentiment':'count'}).reset_index().pivot_table(\n",
    "    values='count',\n",
    "    index=['query','created_at_tz'],\n",
    "    columns=['sentiment'],\n",
    "    aggfunc=np.sum\n",
    ").rename(columns={0:'Negative',1:'Positive'}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "df_lula = df_tweets_analysis[\n",
    "    (df_tweets_analysis['query']=='lula') & ((df_tweets_analysis['created_at_tz']>datetime(2022,3,14).date()) & (df_tweets_analysis['created_at_tz']<datetime(2022,3,25).date()))\n",
    "][['created_at_tz','Negative','Positive']]\n",
    "\n",
    "sns.set()   \n",
    "\n",
    "plt.ylabel('Positive Sentiment')\n",
    "plt.xlabel('Date')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "plt.plot(df_lula.created_at_tz, df_lula['Positive'])\n",
    "plt.plot(df_lula.created_at_tz, df_lula['Negative'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "60c0eae9c48b613b38283907a3e5249fb461fae5c3397c9b6eb4a8c20420e31a"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
