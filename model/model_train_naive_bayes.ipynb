{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers import (\n",
    "    preprocessing\n",
    ")\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StringType, StructField, StructType, IntegerType, DateType, FloatType, ArrayType, LongType, MapType, DateType\n",
    "import warnings\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# instancia spark\n",
    "spark = SparkSession.builder \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .config(\"spark.jars.packages\", \"io.delta:delta-core_2.12:1.1.0\") \\\n",
    "    .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\") \\\n",
    "    .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\") \\\n",
    "    .config(\"spark.executor.memory\",\"4G\") \\\n",
    "    .config(\"spark.driver.memory\",\"4G\") \\\n",
    "    .config(\"spark.executor.cores\",\"12\") \\\n",
    "    .config(\"spark.sql.execution.arrow.pyspark.enabled\",\"true\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base de dados do twitter ja classificada com sentimentos\n",
    "path = \"/home/daholive/Documents/twitter_ellection_brazil_v2/datasource/raw_kaggle/TweetsWithTheme_v2.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframe twitter com sentimentos classificados\n",
    "dataframe = spark.read.options(delimiter=';',header='True').csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label adjust\n",
    "dataframe = dataframe.withColumn(\"sentiment_map\", \n",
    "    F.when(F.col(\"sentiment\")==\"Negativo\", 0).otherwise(1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframe features\n",
    "rdd2 = dataframe.rdd.map(lambda x: (preprocessing(x.tweet_text),len(preprocessing(x.tweet_text).split()),x.sentiment_map))\n",
    "\n",
    "schema = StructType([       \n",
    "    StructField('features', StringType(), True),\n",
    "    StructField('tokens_count', IntegerType(), True),\n",
    "    StructField('label', IntegerType(), True),\n",
    "])\n",
    "\n",
    "df_features = spark.createDataFrame(rdd2, schema = schema)\n",
    "\n",
    "count_map = F.udf( \n",
    "    lambda x: len(x.split()),\n",
    "    IntegerType()     \n",
    ")\n",
    "\n",
    "df_features = df_features \\\n",
    "    .filter(F.col(\"features\")!=\"-\") \\\n",
    "    .filter( count_map(F.col(\"features\"))<30 ) \\\n",
    "    .dropDuplicates(subset = ['features'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = df_features.sampleBy(\"label\", fractions={0: 1, 1: 0.87}, seed=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features and labels\n",
    "features = train.select('features').rdd.flatMap(lambda x: x).collect()\n",
    "labels = np.array(train.select('label').rdd.flatMap(lambda x: x).collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## MODEL TESTS  LogisticRegression\n",
    "from imblearn.metrics import classification_report_imbalanced\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "\n",
    "def tf_idf_features(tokens, num_features):\n",
    "\n",
    "    try:\n",
    "        vectorizer = CountVectorizer(max_features=num_features)\n",
    "        vectorizer.fit(tokens)\n",
    "        X_vectorizer = vectorizer.transform(tokens)\n",
    "\n",
    "        tf_idf_transformer = TfidfTransformer()\n",
    "        tf_idf_transformer.fit(X_vectorizer)\n",
    "        X_train_tf_idf = tf_idf_transformer.transform(X_vectorizer)\n",
    "\n",
    "        return csr_matrix(np.array([np.pad(x, (0, num_features-len(x)), 'constant', constant_values=0) for x in X_train_tf_idf.toarray()]))\n",
    "    \n",
    "    except:\n",
    "        return csr_matrix([np.pad(np.array([0]), (0, 1999), 'constant', constant_values=0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## MODEL TESTS  MultinomialNB\n",
    "\n",
    "def train_and_show_scores(x_features: csr_matrix, num_features: int,y: np.array) -> None:\n",
    "    \n",
    "    X_train_tf_idf = tf_idf_features(x_features, num_features)\n",
    "\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "        X_train_tf_idf, y, train_size=0.7, random_state=42\n",
    "    )\n",
    "\n",
    "    clf = MultinomialNB()\n",
    "\n",
    "    alpha = [100, 10, 1.0, 0.1, 0.01]\n",
    "    grid = dict(alpha=alpha)\n",
    "    \n",
    "    kfold = StratifiedKFold(n_splits = 10, shuffle = True)\n",
    "\n",
    "    random_search_cv = RandomizedSearchCV(\n",
    "        estimator=clf,\n",
    "        param_distributions=grid,\n",
    "        n_jobs=-1, \n",
    "        cv=kfold,\n",
    "        n_iter=20\n",
    "    )\n",
    "\n",
    "    random_search_cv.fit(X_train, y_train)\n",
    "    y_pred_train = random_search_cv.predict(X_train)\n",
    "    y_pred_valid = random_search_cv.predict(X_valid)\n",
    "\n",
    "    print(classification_report_imbalanced(y_train, y_pred_train))\n",
    "    print(classification_report_imbalanced(y_valid, y_pred_valid))\n",
    "\n",
    "    return random_search_cv\n",
    "\n",
    "y_train = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_nb = train_and_show_scores(features,2000,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model prediction with new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_nb.predict_proba(tf_idf_features(['Lula é um péssimo presidente do Brasil','Bolsonaro é ruim'],2000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_nb.predict(tf_idf_features(['Lula é um péssimo presidente do Brasil','Bolsonaro é ruim'],2000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model prediction with new tweets data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_tweets = \"/home/daholive/Documents/twitter_ellection_brazil_v2/datasource/trusted/tweets_preprocessing\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets = spark.read.parquet(path_tweets).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets['tf_idf'] = df_tweets['text_clean'].apply(lambda x: tf_idf_features([x],2000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets['sentiment'] = [model_nb.predict(mtx)[0] for mtx in df_tweets['tf_idf']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets.to_pickle('/home/daholive/Documents/twitter_ellection_brazil_v2/datasource/refined/tweets_naive_bayes/tweets_naive_bayes.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "60c0eae9c48b613b38283907a3e5249fb461fae5c3397c9b6eb4a8c20420e31a"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
