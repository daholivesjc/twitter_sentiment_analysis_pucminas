{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers import (\n",
    "    preprocessing\n",
    ")\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StringType, StructField, StructType, IntegerType, DateType, FloatType, ArrayType, LongType, MapType\n",
    "import warnings\n",
    "import numpy as np \n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import pandas as pd\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bert-for-tf2 in /home/daholive/anaconda3/envs/twiiter_tensor/lib/python3.8/site-packages (0.14.9)\n",
      "Requirement already satisfied: py-params>=0.9.6 in /home/daholive/anaconda3/envs/twiiter_tensor/lib/python3.8/site-packages (from bert-for-tf2) (0.10.2)\n",
      "Requirement already satisfied: params-flow>=0.8.0 in /home/daholive/anaconda3/envs/twiiter_tensor/lib/python3.8/site-packages (from bert-for-tf2) (0.8.2)\n",
      "Requirement already satisfied: tqdm in /home/daholive/anaconda3/envs/twiiter_tensor/lib/python3.8/site-packages (from params-flow>=0.8.0->bert-for-tf2) (4.64.0)\n",
      "Requirement already satisfied: numpy in /home/daholive/anaconda3/envs/twiiter_tensor/lib/python3.8/site-packages (from params-flow>=0.8.0->bert-for-tf2) (1.22.3)\n",
      "Requirement already satisfied: transformers in /home/daholive/anaconda3/envs/twiiter_tensor/lib/python3.8/site-packages (4.21.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/daholive/anaconda3/envs/twiiter_tensor/lib/python3.8/site-packages (from transformers) (4.64.0)\n",
      "Requirement already satisfied: requests in /home/daholive/anaconda3/envs/twiiter_tensor/lib/python3.8/site-packages (from transformers) (2.27.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/daholive/anaconda3/envs/twiiter_tensor/lib/python3.8/site-packages (from transformers) (2022.3.15)\n",
      "Requirement already satisfied: filelock in /home/daholive/anaconda3/envs/twiiter_tensor/lib/python3.8/site-packages (from transformers) (3.7.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/daholive/anaconda3/envs/twiiter_tensor/lib/python3.8/site-packages (from transformers) (5.4.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/daholive/anaconda3/envs/twiiter_tensor/lib/python3.8/site-packages (from transformers) (1.22.3)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /home/daholive/anaconda3/envs/twiiter_tensor/lib/python3.8/site-packages (from transformers) (0.8.1)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /home/daholive/anaconda3/envs/twiiter_tensor/lib/python3.8/site-packages (from transformers) (0.12.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/daholive/anaconda3/envs/twiiter_tensor/lib/python3.8/site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/daholive/anaconda3/envs/twiiter_tensor/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/daholive/anaconda3/envs/twiiter_tensor/lib/python3.8/site-packages (from packaging>=20.0->transformers) (3.0.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/daholive/anaconda3/envs/twiiter_tensor/lib/python3.8/site-packages (from requests->transformers) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/daholive/anaconda3/envs/twiiter_tensor/lib/python3.8/site-packages (from requests->transformers) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/daholive/anaconda3/envs/twiiter_tensor/lib/python3.8/site-packages (from requests->transformers) (1.26.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/daholive/anaconda3/envs/twiiter_tensor/lib/python3.8/site-packages (from requests->transformers) (2.0.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install bert-for-tf2\n",
    "!pip install -U transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base de dados do twitter ja classificada com sentimentos\n",
    "path = \"/home/daholive/Documents/twitter_ellection_brazil_v2/datasource/raw_kaggle/NoThemeTweets.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframe twitter com sentimentos classificados\n",
    "df = pd.read_csv(path, error_bad_lines=False, sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_treated_data(\n",
    "    dataset, \n",
    "    cols, \n",
    "    cols_drop = [], \n",
    "    col_to_change='sentiment', \n",
    "    val_col_change = {\"Negativo\": 0, \"Positivo\":1}\n",
    "):\n",
    " \n",
    "    # 2. Rename columns\n",
    "    dataset.columns = cols\n",
    "    \n",
    "    # 3. Drop columns not needed\n",
    "    dataset.drop(cols_drop, axis=1, inplace=True)\n",
    "    \n",
    "    # 3.1 Drop all rows with at least one element is missing\n",
    "    dataset.dropna()\n",
    "    \n",
    "    # 4. Convert setiments from \"Negative/Positive\" to \"0/1\" \n",
    "    dataset.replace({col_to_change: val_col_change}, inplace=True)\n",
    "    \n",
    "    # Return our dataset\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_cols = [\"id\", \"text\", \"date\", \"sentiment\", \"query\"]\n",
    "\n",
    "default_drop_cols = [\"id\", \"date\", \"query\"]\n",
    "\n",
    "# class_names = ['Negativo', 'Positive']\n",
    "df = get_treated_data(df, default_cols, cols_drop = default_drop_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.665179\n",
       "1    0.334821\n",
       "Name: sentiment, dtype: float64"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take a peek at the dataset\n",
    "df[\"sentiment\"].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    \n",
    "    # Not needed to be imported globally\n",
    "    from bs4 import BeautifulSoup\n",
    "    import re\n",
    "    text = BeautifulSoup(text, \"lxml\").get_text()\n",
    "    text = re.sub(r'^https?:\\/\\/.*[\\r\\n]*', '', text, flags=re.MULTILINE) # Remove urls\n",
    "    text = re.sub(r\"@[A-Za-z0-9]+\", ' ', text)\n",
    "    text = re.sub(r\"https?://[A-Za-z0-9./]+\", ' ', text)\n",
    "    text = re.sub(r\"[^a-zA-Z.!?']\", ' ', text)\n",
    "    text = re.sub(r\" +\", ' ', text)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text'].apply(lambda text: preprocess_text(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>para eu ir</td>\n",
       "      <td>Positivo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>O meu like eu j dei na poca</td>\n",
       "      <td>Positivo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Eu s queria conseguir comer alguma coisa pra p...</td>\n",
       "      <td>Positivo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>D que lindo dia !</td>\n",
       "      <td>Positivo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Resmungao Pq da pr jeito!! uma oferta ha q ap...</td>\n",
       "      <td>Positivo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text sentiment\n",
       "0                                        para eu ir   Positivo\n",
       "1                       O meu like eu j dei na poca   Positivo\n",
       "2  Eu s queria conseguir comer alguma coisa pra p...  Positivo\n",
       "3                                  D que lindo dia !  Positivo\n",
       "4   Resmungao Pq da pr jeito!! uma oferta ha q ap...  Positivo"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of rows and columns in the dataset is: (785814, 2)\n"
     ]
    }
   ],
   "source": [
    "print(\"The number of rows and columns in the dataset is: {}\".format(df.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text         0\n",
       "sentiment    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Identify missing values\n",
    "df.apply(lambda x: sum(x.isnull()), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Negativo    0.665179\n",
       "Positivo    0.334821\n",
       "Name: sentiment, dtype: float64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the target class balance\n",
    "df[\"sentiment\"].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: | \n",
      "The environment is inconsistent, please check the package plan carefully\n",
      "The following packages are causing the inconsistency:\n",
      "\n",
      "  - defaults/linux-64::tensorflow-gpu==2.4.1=h30adc30_0\n",
      "  - defaults/linux-64::tensorflow==2.4.1=gpu_py38h8a7d6ce_0\n",
      "  - defaults/linux-64::tensorflow-base==2.4.1=gpu_py38h29c2da4_0\n",
      "  - defaults/linux-64::h5py==2.10.0=py38hd6299e0_1\n",
      "  - defaults/linux-64::numpy==1.21.2=py38h20f2e39_0\n",
      "  - defaults/linux-64::mkl_random==1.2.2=py38h51133e4_0\n",
      "  - defaults/noarch::tensorflow-estimator==2.6.0=pyh7b7c402_0\n",
      "  - defaults/noarch::opt_einsum==3.3.0=pyhd3eb1b0_1\n",
      "  - defaults/noarch::tensorboard==2.4.0=pyhc547734_0\n",
      "  - defaults/noarch::keras-preprocessing==1.1.2=pyhd3eb1b0_0\n",
      "  - defaults/linux-64::mkl_fft==1.3.1=py38hd3c417c_0\n",
      "done\n",
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 4.12.0\n",
      "  latest version: 4.13.0\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c defaults conda\n",
      "\n",
      "\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /home/daholive/anaconda3/envs/twiiter_tensor\n",
      "\n",
      "  added / updated specs:\n",
      "    - pytorch\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    ca-certificates-2022.07.19 |       h06a4308_0         124 KB\n",
      "    certifi-2022.6.15          |   py38h06a4308_0         153 KB\n",
      "    future-0.18.2              |           py38_1         632 KB\n",
      "    ninja-1.10.2               |       h06a4308_5           8 KB\n",
      "    ninja-base-1.10.2          |       hd09550d_5         109 KB\n",
      "    numpy-1.21.5               |   py38he7a7128_2          10 KB\n",
      "    numpy-base-1.21.5          |   py38hf524024_2         4.8 MB\n",
      "    openssl-1.1.1q             |       h7f8727e_0         2.5 MB\n",
      "    pytorch-1.10.2             |cpu_py38hfa7516b_0        43.9 MB\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:        52.3 MB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  future             pkgs/main/linux-64::future-0.18.2-py38_1\n",
      "  ninja              pkgs/main/linux-64::ninja-1.10.2-h06a4308_5\n",
      "  ninja-base         pkgs/main/linux-64::ninja-base-1.10.2-hd09550d_5\n",
      "  numpy-base         pkgs/main/linux-64::numpy-base-1.21.5-py38hf524024_2\n",
      "  pytorch            pkgs/main/linux-64::pytorch-1.10.2-cpu_py38hfa7516b_0\n",
      "  scipy              pkgs/main/linux-64::scipy-1.7.3-py38hc147768_0\n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "  ca-certificates                      2022.3.29-h06a4308_0 --> 2022.07.19-h06a4308_0\n",
      "  certifi                          2021.10.8-py38h06a4308_2 --> 2022.6.15-py38h06a4308_0\n",
      "  numpy                               1.21.2-py38h20f2e39_0 --> 1.21.5-py38he7a7128_2\n",
      "  openssl                                 1.1.1n-h7f8727e_0 --> 1.1.1q-h7f8727e_0\n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "ninja-1.10.2         | 8 KB      | ##################################### | 100% \n",
      "numpy-base-1.21.5    | 4.8 MB    | ##################################### | 100% \n",
      "future-0.18.2        | 632 KB    | ##################################### | 100% \n",
      "openssl-1.1.1q       | 2.5 MB    | ##################################### | 100% \n",
      "pytorch-1.10.2       | 43.9 MB   | ##################################### | 100% \n",
      "ca-certificates-2022 | 124 KB    | ##################################### | 100% \n",
      "numpy-1.21.5         | 10 KB     | ##################################### | 100% \n",
      "ninja-base-1.10.2    | 109 KB    | ##################################### | 100% \n",
      "certifi-2022.6.15    | 153 KB    | ##################################### | 100% \n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n"
     ]
    }
   ],
   "source": [
    "!conda install -y PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModel, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c21564f46514736b590fb4aaa18dd44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer_config.json:   0%|          | 0.00/43.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58bc57bce5b94a3a8f4c7dff9ad56d4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading config.json:   0%|          | 0.00/647 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ed746ed03064abe8ccb5a84d9842d94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading vocab.txt:   0%|          | 0.00/205k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d089a9ef98e4ba9babc5168516dca82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading added_tokens.json:   0%|          | 0.00/2.00 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18c995514c5f4a3281da57438b86d0f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ImportError",
     "evalue": "\nAutoModel requires the PyTorch library but it was not found in your environment.\nHowever, we were able to find a TensorFlow installation. TensorFlow classes begin\nwith \"TF\", but are otherwise identically named to our PyTorch classes. This\nmeans that the TF equivalent of the class you tried to import would be \"TFAutoModel\".\nIf you want to use TensorFlow, please use TF classes instead!\n\nIf you really do want to use PyTorch please go to\nhttps://pytorch.org/get-started/locally/ and follow the instructions that\nmatch your environment.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_10328/1254006199.py\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# BERT Base\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'neuralmind/bert-base-portuguese-cased'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'neuralmind/bert-base-portuguese-cased'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/twiiter_tensor/lib/python3.8/site-packages/transformers/utils/import_utils.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(cls, key)\u001b[0m\n\u001b[1;32m    916\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"_\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 918\u001b[0;31m         \u001b[0mrequires_backends\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backends\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/twiiter_tensor/lib/python3.8/site-packages/transformers/utils/import_utils.py\u001b[0m in \u001b[0;36mrequires_backends\u001b[0;34m(obj, backends)\u001b[0m\n\u001b[1;32m    895\u001b[0m     \u001b[0;31m# Raise an error for users who might not realize that classes without \"TF\" are torch-only\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    896\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m\"torch\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbackends\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"tf\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbackends\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_torch_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_tf_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 897\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPYTORCH_IMPORT_ERROR_WITH_TF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    898\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m     \u001b[0;31m# Raise the inverse error for PyTorch users trying to load TF classes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: \nAutoModel requires the PyTorch library but it was not found in your environment.\nHowever, we were able to find a TensorFlow installation. TensorFlow classes begin\nwith \"TF\", but are otherwise identically named to our PyTorch classes. This\nmeans that the TF equivalent of the class you tried to import would be \"TFAutoModel\".\nIf you want to use TensorFlow, please use TF classes instead!\n\nIf you really do want to use PyTorch please go to\nhttps://pytorch.org/get-started/locally/ and follow the instructions that\nmatch your environment.\n"
     ]
    }
   ],
   "source": [
    "# BERT Base\n",
    "tokenizer = AutoTokenizer.from_pretrained('neuralmind/bert-base-portuguese-cased')\n",
    "model = AutoModel.from_pretrained('neuralmind/bert-base-portuguese-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "60c0eae9c48b613b38283907a3e5249fb461fae5c3397c9b6eb4a8c20420e31a"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
